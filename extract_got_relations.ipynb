{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to get an OPENAI Key\n",
    "To get an OpenAI API key, you need to sign up for an account on the OpenAI website. Here are the steps:\n",
    "\n",
    "Go to the OpenAI website.\n",
    "Click on \"Sign Up\" to create a new account.\n",
    "After you've signed up and logged in, navigate to the API section.\n",
    "Here, you should see your API key. This is a long string of characters that allows you to authenticate with the OpenAI API.\n",
    "Remember to keep your API key secret. Don't share it with anyone, and don't publish it in public places like GitHub. If you believe your API key has been compromised, you can regenerate it from the same API section in your OpenAI account.\n",
    "\n",
    "Please note that usage of the OpenAI API may be subject to fees. Make sure to review the pricing details and terms of service on the OpenAI website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "class LLM:\n",
    "    def __init__(self, open_ai_key=False, model=None, temperature=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            OpenAI_key (str, optional): If you provide a key OpenAI will be used. Defaults to False.\n",
    "            model (str, optional): The model to use. Defaults to None.\n",
    "            temperature (int, optional): The temperature for generating text. Defaults to 0.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.temeprature = temperature\n",
    "        if open_ai_key:\n",
    "\n",
    "            self.llm = OpenAI\n",
    "            self.client = OpenAI(api_key=open_ai_key)\n",
    "            self.openai = True\n",
    "            self.ollama = False\n",
    "            if not model:\n",
    "                self.model = \"gpt-3.5-turbo\"\n",
    "\n",
    "\n",
    "    def generate(self, prompt):\n",
    "        chat_completion = self.client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=self.model,\n",
    "        )\n",
    "\n",
    "        answer = chat_completion.choices[0].message.content\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'open_ai_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initiate the LLM class\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m llm \u001b[38;5;241m=\u001b[39m LLM(\u001b[43mopen_ai_key\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<API_KEY_HERE>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'open_ai_key' is not defined"
     ]
    }
   ],
   "source": [
    "# Initiate the LLM class\n",
    "llm = LLM(open_ai_key='<API_KEY_HERE>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the text\n",
    "1. Import the text.\n",
    "2. Split it into episodes.\n",
    "3. Make a dictionary of the episodes like {episode_name: episode_text}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract all relations from the chunks\n",
    "1. Define a function to extract relations\n",
    "2. Try out a working prompt.\n",
    "3. Loop throuh the chunks to create a list of relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get more information on every relation\n",
    "1. Define a function to extract information about a relation.\n",
    "2. Try out a working prompt.\n",
    "3. Loop though the relations to add intormation to each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare networkx\n",
    "1. Install networkx with ```%pip install networkx```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export a network file for use with Gephi\n",
    "1. Import the networkx module.\n",
    "2. Create the graph.\n",
    "3. Export a .gexf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
